{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6d25d5-6049-407b-b2f7-2601b605979f",
   "metadata": {},
   "source": [
    "# Dog classification model \n",
    "## Based upon the stanford dogs dataset\n",
    "\n",
    "This coursework aims to create a convolutional neural network using keras and tensorflow upon the stanford dogs dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb4d9c-7098-4844-8d1c-dc7a16b5866c",
   "metadata": {},
   "source": [
    "## Move images into one directory\n",
    "Below is a python script to move all of the code within the stanford dogs dataset into one folder without the sub folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4d097ae-535b-49d9-a433-c5623454a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_images(source_folder, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Walk through the source folder\n",
    "    for root, _, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            # Check if the file is an image file (you can add more extensions if needed)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                source_path = os.path.join(root, file)\n",
    "                # Move the image file to the destination folder\n",
    "                shutil.move(source_path, destination_folder)\n",
    "\n",
    "source_folder = 'images'  # Replace with the path to your images folder\n",
    "destination_folder = 'stanford_dataset'  # Replace with the desired destination path\n",
    "\n",
    "move_images(source_folder, destination_folder)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d2821-0060-4b18-af9d-26c30d815b17",
   "metadata": {},
   "source": [
    "## Normalize images\n",
    "We now need to normalize all images so that they are the same height & width and rgb etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ce306bb-2369-4e0e-919f-e73a9a8958ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed0b5837-20e3-4c9e-96ca-0d6d2e3ac0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Stanford Dogs dataset\n",
    "data_dir = 'stanford_dataset'\n",
    "\n",
    "# Function to normalize images\n",
    "def normalize_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file_path.endswith('.jpg') or file_path.endswith('.png'):\n",
    "                img = cv2.imread(file_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (150, 150))  # Resize image if necessary\n",
    "                    img = img.astype('float32') / 255.0  # Normalize pixel values between 0 and 1\n",
    "                    cv2.imwrite(file_path, img * 255)  # Save normalized image\n",
    "\n",
    "# Normalize all the images in the dataset\n",
    "normalize_images(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655bc96-d7f6-4c0c-8a72-e203d88b7986",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "Now to split the dataset into trainning data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66d64b41-4cf8-49a2-bcbd-2e18cedb390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Function to split images into training and validation sets\n",
    "def split_data(src, train_dest, val_dest, split_ratio=0.7):\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        # Create similar directory structure in training and validation folders\n",
    "        relative_path = os.path.relpath(root, src)\n",
    "        train_dir = os.path.join(train_dest, relative_path)\n",
    "        val_dir = os.path.join(val_dest, relative_path)\n",
    "\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "        images = [file for file in files if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        train_count = math.ceil(len(images) * split_ratio)\n",
    "        train_images = images[:train_count]\n",
    "        val_images = images[train_count:]\n",
    "\n",
    "        for img in train_images:\n",
    "            src_path = os.path.join(root, img)\n",
    "            dest_path = os.path.join(train_dir, img)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "        for img in val_images:\n",
    "            src_path = os.path.join(root, img)\n",
    "            dest_path = os.path.join(val_dir, img)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Define paths\n",
    "main_dir = \"Images\"\n",
    "training_data_dir = \"training_data\"\n",
    "validation_data_dir = \"validation_data\"\n",
    "\n",
    "# Split data\n",
    "split_data(main_dir, training_data_dir, validation_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8df8f3-819c-4bd4-bd51-793bd2957005",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "Time to create the model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0936ad-529f-4953-aa63-c113db81cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements for tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6978e51c-8cf3-48c4-babc-472234c28d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               18940416  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 120)               61560     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,095,224\n",
      "Trainable params: 19,095,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "input_shape = (150, 150, 3)  # Input image dimensions\n",
    "num_classes = 120  # Number of classes in the dataset\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05cb3cb7-318f-4cbb-9383-2856e5255082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# make the model use a gpu\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182039d-f93b-43be-8b58-38efc2fd0d32",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Now its time to execute code to train the model on the stanford normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1b581-fc53-4100-9aa3-ba3b08aa27c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14458 images belonging to 120 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x7fecca3cd610>\n",
      "Found 6122 images belonging to 120 classes.\n",
      "Epoch 1/10\n",
      "145/290 [==============>...............] - ETA: 1:31 - loss: 4.7664 - accuracy: 0.0137"
     ]
    }
   ],
   "source": [
    "# Assuming you have your training and validation data prepared as train_data and validation_data\n",
    "# Replace 'train_data' and 'validation_data' with your actual datasets\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Directories containing training and validation data\n",
    "train_dir = 'training_data'\n",
    "validation_dir = 'validation_data'\n",
    "\n",
    "# Data generators for training and validation data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Define number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "# Flow training images in batches using train_datagen\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'  # Use 'sparse' for sparse_categorical_crossentropy loss\n",
    ")\n",
    "\n",
    "print(train_data)\n",
    "\n",
    "\n",
    "# Flow validation images in batches using validation_datagen\n",
    "validation_data = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'  # Use 'sparse' for sparse_categorical_crossentropy loss\n",
    ")\n",
    "\n",
    "\n",
    "#set the data\n",
    "\n",
    "# Fitting the model to the dataset\n",
    "history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
